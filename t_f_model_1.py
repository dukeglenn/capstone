# -*- coding: utf-8 -*-
"""T/F model 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gMjiuN6tJzdIpGUj8c648E2QxRt08AlN
"""

import pickle
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Load, preprocess and encode data
file_path = 'test_opinions.xlsx'
df = pd.read_excel(file_path, sheet_name='Sheet1')

df = df.map(lambda x: str(x).lower() if isinstance(x, str) else x)
df = df.replace({'t': 1, 'f': 0})
df = df.infer_objects(copy=False)
label_encoder = LabelEncoder()
df["Vict/Perp(v/p)"] = label_encoder.fit_transform(df["Vict/Perp(v/p)"])

# Feature Engineering
X = df.drop(columns=['Vict/Perp(v/p)'])
y = df['Vict/Perp(v/p)']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# Define the parameter grid for Grid Search
param_grid = {
    'n_estimators': [50, 100, 200],  # Number of trees in the forest
    'max_depth': [None, 10, 20],  # Maximum depth of the tree
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node
    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node
    'bootstrap': [True, False]  # Whether bootstrap samples are used
}

# Initialize the RandomForestClassifier
model = RandomForestClassifier(random_state=42)

# Initialize Grid Search with cross-validation
grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring='accuracy'
)

# Perform Grid Search to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model and its parameters
best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

print("Best Hyperparameters:", best_params)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)

# Cross-validation for more robust evaluation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='accuracy')

# Output Results
print(f'Model Accuracy: {accuracy_score(y_test, y_pred):.2f}')
print(f'Cross-Validation Accuracy: {np.mean(cv_scores):.2f}')
print(classification_report(y_test, y_pred))

# Feature Importance Analysis
feature_importances = pd.DataFrame(
    best_model.feature_importances_, index=X.columns, columns=["Importance"]
).sort_values(by="Importance", ascending=False)
print("Feature Importances:\n", feature_importances)

# Example Prediction
example = pd.DataFrame({
    'victim_negligence': [0],
    'victim_em_doc': [0],
    'victim_serious_injury': [1],
    'perp_negligence': [1],
    'perp_em_doc': [0],
    'perp_serious_injury': [0]
})

prediction = best_model.predict(example)
print(f'Prediction for example: {label_encoder.inverse_transform(prediction)[0]}')

with open('model.pkl', 'wb') as f:
    pickle.dump(best_model, f)